name: Automatización de scraping web

on:
  schedule:
    - cron: '0 0 * * 1'  # Ejecutar todos los lunes
  
  workflow_dispatch:      # Permitir ejecución manual

jobs:

  build:
    runs-on: ubuntu-latest

    env:
      EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
      EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      DESTINATARIO_EMAIL: ${{ secrets.DESTINATARIO_EMAIL }}

    steps:

    - name: Checkout code
      run: |
        git clone https://github.com/RickyFer22/Web-Scraping-Automatizado-para-la-Vigilancia-de-Competidores.git .
        git checkout ${{ github.ref }}

    - name: Instalar dependencias
      run: pip install -r requirements.txt

    - name: Instalar Firefox
      run: |
        sudo apt-get update
        sudo apt-get install -y firefox

    - name: Descargar geckodriver
      run: |
        wget https://github.com/mozilla/geckodriver/releases/download/v0.34.0/geckodriver-v0.34.0-linux64.tar.gz
        tar -xvzf geckodriver-v0.34.0-linux64.tar.gz
        chmod +x geckodriver
        sudo mv geckodriver /usr/local/bin/

    - name: Verificar la instalación de geckodriver
      run: geckodriver --version

    - name: Configurar Xvfb
      run: |
        sudo apt-get install -y xvfb
        Xvfb :99 &
        echo "DISPLAY=:99.0" >> $GITHUB_ENV

    - name: Ejecutar scripts de scraping
      run: |
        for file in *.py; do
          python "$file"
        done

    - name: Subir base de datos
      uses: actions/upload-artifact@v3
      with:
        name: precios_competencia.db
        path: precios_competencia.db

    - name: Generar y subir Excel
      run: |
        python 6listas_en_excel.py

    - name: Subir archivo Excel
      uses: actions/upload-artifact@v3
      with:
        name: precios_competencia.xlsx
        path: precios_competencia.xlsx



