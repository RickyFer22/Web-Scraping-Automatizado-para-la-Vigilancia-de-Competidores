name: Automatización de scraping web

on:
  schedule:
    - cron: '0 0 * * 1' # Ejecutar todos los lunes
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    env:
      EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
      EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      DESTINATARIO_EMAIL: ${{ secrets.DESTINATARIO_EMAIL }}

    steps:
    # Clonar el repositorio
    - name: Clonar el repositorio
      run: |
        git clone https://github.com/RickyFer22/Web-Scraping-Automatizado-para-la-Vigilancia-de-Competidores.git .
        git checkout ${{ github.ref }}

    # Instalar dependencias
    - name: Instalar dependencias
      run: pip install -r requirements.txt

    # Verificar si la página está disponible antes de ejecutar el scraping
    - name: Verificar disponibilidad de la página
      run: |
        if curl -Is https://electropunto.com.ar | head -n 1 | grep "200\|301\|302"; then
          echo "Página en línea, ejecutando scraping..."
        else
          echo "Página en reparación, saliendo del workflow."
          exit 0
        fi

    # Instalar Firefox
    - name: Instalar Firefox
      uses: browser-actions/setup-firefox@v1
      with:
        firefox-version: 'latest'

    # Descargar GeckoDriver
    - name: Descargar GeckoDriver
      run: |
        GECKODRIVER_VERSION=$(curl -s https://api.github.com/repos/mozilla/geckodriver/releases/latest | grep tag_name | cut -d '"' -f 4)
        wget https://github.com/mozilla/geckodriver/releases/download/$GECKODRIVER_VERSION/geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz
        tar -xvzf geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz
        chmod +x geckodriver
        sudo mv geckodriver /usr/local/bin/

    # Verificar instalación de GeckoDriver
    - name: Verificar instalación de GeckoDriver
      run: geckodriver --version

    # Configurar Xvfb para entorno sin pantalla
    - name: Configurar Xvfb
      run: |
        sudo apt-get install -y xvfb
        Xvfb :99 &
        echo "DISPLAY=:99.0" >> $GITHUB_ENV

    # Ejecutar scripts de scraping
    - name: Ejecutar scripts de scraping
      run: |
        for file in *.py; do
          if [ -f "$file" ]; then
            python "$file"
          fi
        done

    # Generar Excel de resultados
    - name: Generar y guardar Excel
      run: python 6listas_en_excel.py

    # Enviar el archivo Excel por correo electrónico
    - name: Enviar resultados por correo
      env:
        EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        DESTINATARIO_EMAIL: ${{ secrets.DESTINATARIO_EMAIL }}
      run: |
        python - <<EOF
        import smtplib
        from email.mime.multipart import MIMEMultipart
        from email.mime.base import MIMEBase
        from email import encoders

        # Configuración del correo
        email_address = "${{ secrets.EMAIL_ADDRESS }}"
        email_password = "${{ secrets.EMAIL_PASSWORD }}"
        destinatario = "${{ secrets.DESTINATARIO_EMAIL }}"
        asunto = "Resultados de Scraping"
        mensaje = "Se adjuntan los resultados del scraping en formato Excel."

        # Crear el mensaje
        msg = MIMEMultipart()
        msg['From'] = email_address
        msg['To'] = destinatario
        msg['Subject'] = asunto

        # Adjuntar archivo
        archivo = "precios_competencia.xlsx"
        with open(archivo, 'rb') as adj:
            parte = MIMEBase('application', 'octet-stream')
            parte.set_payload(adj.read())
        encoders.encode_base64(parte)
        parte.add_header('Content-Disposition', f'attachment; filename={archivo}')
        msg.attach(parte)

        # Enviar correo
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(email_address, email_password)
            server.sendmail(email_address, destinatario, msg.as_string())
        EOF



